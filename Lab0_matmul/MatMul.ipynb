{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO_Gbjref6LQ",
        "outputId": "93308b68-ea7d-4115-acd8-01a0ff67c000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 20 17:55:03 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXoVSif3gqth",
        "outputId": "241b40b6-c77b-420f-e141-f66c2de6e086"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.14-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.1)\n",
            "Downloading pytools-2024.1.14-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660545 sha256=67853d871e9b78be91c3abbfac4338dc50ba662947b5c8f994bc9df417f8cbf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.5 pycuda-2024.1.2 pytools-2024.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytoOWybxg-n7",
        "outputId": "7989f417-c7cd-4663-e3a2-3aa1d7c96987"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "from pycuda import driver, gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "b1IiLoh2g_Mo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU CUDA ядро\n",
        "mod = SourceModule(\"\"\"\n",
        "        __global__ void mult_gpu(double* A, double* B, double* C){\n",
        "                const int row =  threadIdx.y + blockIdx.y * blockDim.y;\n",
        "                const int column = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "                const int N = 2000;\n",
        "                for(int i = 0; i < N; i++){\n",
        "                        C[column + row * N] += A[i + row * N] * B[column + i * N];\n",
        "                }\n",
        "        }\n",
        "\"\"\")\n",
        "\n",
        "# CPU перемножение через циклы\n",
        "def mult_cpu(A, B):\n",
        "    C, n  = np.zeros((N, N)), range(N)\n",
        "    for i in n:\n",
        "        for j in n:\n",
        "            for k in n:\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "    return C"
      ],
      "metadata": {
        "id": "yqHnomsohBsK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [200, 500, 1000, 2000]\n",
        "N = sizes[3]\n",
        "\n",
        "A = np.random.randn(N, N)\n",
        "B = np.random.randn(N, N)\n",
        "C_gpu = np.ones((N, N))\n"
      ],
      "metadata": {
        "id": "5GfSynT2hGPK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU перемножение\n",
        "\n",
        "# создание блока и сетки для функции CUDA\n",
        "block_size = [2, 2]\n",
        "block, grid = (block_size[0], block_size[1], 1), (int((N + block_size[0] - 1) / 2), int((N + block_size[1] - 1) / 2))\n",
        "mult = mod.get_function(\"mult_gpu\")\n",
        "\n",
        "# запуск функции и засекание времени\n",
        "start_gpu = time.time()\n",
        "mult(driver.In(A), driver.In(B), driver.Out(C_gpu), block = block, grid = grid)\n",
        "driver.Context.synchronize()\n",
        "time_gpu = time.time() - start_gpu"
      ],
      "metadata": {
        "id": "ngutBGpfhH-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e0dee2-172e-4af8-fe36-4a9f09ceb82a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU перемножение\n",
        "start_cpu = time.time()\n",
        "C_cpu = mult_cpu(A, B)\n",
        "time_cpu = time.time() - start_cpu"
      ],
      "metadata": {
        "id": "GsyKuvu1hKCB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Результаты\n",
        "print(f'GPU время выполнения: {time_gpu}')\n",
        "print(f'CPU время выполнения: {time_cpu}')\n",
        "print(f'Во сколько раз быстрее на GPU: time_cpu/time_gpu = {time_cpu/time_gpu}')\n",
        "\n",
        "# Матрица С_np посчитана с помощью numpy.dot для проверки корректности результатов\n",
        "C_np = np.dot(A,B)\n",
        "if np.allclose(C_cpu, C_np) and np.allclose(C_gpu, C_np):\n",
        "  print('Функции перемножения на CPU и GPU посчитали корректно')\n",
        "else:\n",
        "  print('Результаты не сходятся с проверкой numpy.dot()')\n",
        "\n",
        "#print(f\"C_gpu: {C_gpu} \\n C_cpu: {C_cpu} \\n C_np: {C_np}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5imWDkY5hL2K",
        "outputId": "54f165ce-f504-4e93-c8ec-a5a3720dbc7a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU время выполнения: 1.4184284210205078\n",
            "CPU время выполнения: 5014.554000854492\n",
            "Во сколько раз быстрее на GPU: time_cpu/time_gpu = 3535.288722744784\n",
            "Функции перемножения на CPU и GPU посчитали корректно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CPU_times = np.zeros(5)\n",
        "GPU_times = np.zeros(5)"
      ],
      "metadata": {
        "id": "zkDf2Op1lI-d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сделаем массивы, содержащие время выполнения (при изменении индекса и N, результаты записываются по очереди)\n",
        "CPU_times[3] = time_cpu\n",
        "GPU_times[3] = time_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVW46wGcm3zV",
        "outputId": "9459748d-8386-4fbf-d9c7-7b167fac02a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00494742, 0.02683139, 0.22877789, 1.41842842, 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Сделаем красивую таблицу\n",
        "table = PrettyTable(['Размер матриц', 'Время CPU', 'Время GPU', 'Ускорение'])\n",
        "table.align = 'l'\n",
        "table.add_row(['200x200', CPU_times[0], GPU_times[0], CPU_times[0]/GPU_times[0] ])\n",
        "table.add_row(['500x500', CPU_times[1], GPU_times[1], CPU_times[1]/GPU_times[1] ])\n",
        "table.add_row(['1000x1000', CPU_times[2], GPU_times[2], CPU_times[2]/GPU_times[2] ])\n",
        "table.add_row(['2000x2000', CPU_times[3], GPU_times[3], CPU_times[3]/GPU_times[3] ])\n",
        "print(table)"
      ],
      "metadata": {
        "id": "fd99Km8hkcIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a5e913-c032-427a-e3db-69812b26bf00"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------------+-----------------------+-------------------+\n",
            "| Размер матриц | Время CPU         | Время GPU             | Ускорение         |\n",
            "+---------------+-------------------+-----------------------+-------------------+\n",
            "| 200x200       | 4.512691020965576 | 0.0049474239349365234 | 912.1294395450822 |\n",
            "| 500x500       | 78.94668793678284 | 0.026831388473510742  | 2942.325851482597 |\n",
            "| 1000x1000     | 636.0277841091156 | 0.22877788543701172   | 2780.110424109283 |\n",
            "| 2000x2000     | 5014.554000854492 | 1.4184284210205078    | 3535.288722744784 |\n",
            "+---------------+-------------------+-----------------------+-------------------+\n"
          ]
        }
      ]
    }
  ]
}